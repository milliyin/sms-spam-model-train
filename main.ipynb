{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34af469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from huggingface_hub import HfFolder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03a0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_TOKEN = \"hf...\"\n",
    "HfFolder.save_token(HF_TOKEN)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90a88ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 5574/5574 [00:00<00:00, 501804.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"ucirvine/sms_spam\")\n",
    "ds.save_to_disk(\"E:/2.code-on-fire/3.ML/Sms-Spam/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ac5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"E:/2.code-on-fire/3.ML/Sms-Spam/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c323f84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][:0][\"sms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb09b4",
   "metadata": {},
   "source": [
    "Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24b4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(dtype=np.float32)\n",
    "X = cv.fit_transform(ds[\"train\"][0:][\"sms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63c2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()\n",
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y= np.array(ds[\"train\"][\"label\"])\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1ae636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459 1115 4459 1115\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0] ,X_test.shape[0] ,len(y_train) ,len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4dc8c1",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e5bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CircleModelV0(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=8713, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CircleModelV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(8713, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model_0 = CircleModelV0().to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de58acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "y_logits = model_0(X_test.to(device))[:5]\n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_preds = torch.round(y_pred_probs)\n",
    "y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))\n",
    "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
    "y_preds.squeeze()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd18f2",
   "metadata": {},
   "source": [
    "Traning and testinggg loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b97725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.67886, Accuracy: 86.70% | Test loss: 0.66974, Test acc: 86.01%\n",
      "Epoch: 10 | Loss: 0.56483, Accuracy: 97.78% | Test loss: 0.56147, Test acc: 96.68%\n",
      "Epoch: 20 | Loss: 0.43694, Accuracy: 99.08% | Test loss: 0.44372, Test acc: 97.76%\n",
      "Epoch: 30 | Loss: 0.32340, Accuracy: 99.35% | Test loss: 0.34034, Test acc: 98.12%\n",
      "Epoch: 40 | Loss: 0.23549, Accuracy: 99.55% | Test loss: 0.26125, Test acc: 98.12%\n",
      "Epoch: 50 | Loss: 0.17286, Accuracy: 99.64% | Test loss: 0.20590, Test acc: 98.12%\n",
      "Epoch: 60 | Loss: 0.12957, Accuracy: 99.71% | Test loss: 0.16871, Test acc: 98.12%\n",
      "Epoch: 70 | Loss: 0.09960, Accuracy: 99.82% | Test loss: 0.14387, Test acc: 98.21%\n",
      "Epoch: 80 | Loss: 0.07851, Accuracy: 99.91% | Test loss: 0.12708, Test acc: 98.03%\n",
      "Epoch: 90 | Loss: 0.06333, Accuracy: 99.91% | Test loss: 0.11549, Test acc: 98.12%\n",
      "Epoch: 100 | Loss: 0.05212, Accuracy: 99.93% | Test loss: 0.10733, Test acc: 98.12%\n",
      "Epoch: 110 | Loss: 0.04364, Accuracy: 99.93% | Test loss: 0.10148, Test acc: 98.12%\n",
      "Epoch: 120 | Loss: 0.03711, Accuracy: 99.96% | Test loss: 0.09721, Test acc: 98.12%\n",
      "Epoch: 130 | Loss: 0.03200, Accuracy: 99.98% | Test loss: 0.09405, Test acc: 98.12%\n",
      "Epoch: 140 | Loss: 0.02791, Accuracy: 99.98% | Test loss: 0.09170, Test acc: 98.12%\n",
      "Epoch: 150 | Loss: 0.02457, Accuracy: 99.98% | Test loss: 0.08994, Test acc: 98.21%\n",
      "Epoch: 160 | Loss: 0.02182, Accuracy: 99.98% | Test loss: 0.08862, Test acc: 98.21%\n",
      "Epoch: 170 | Loss: 0.01951, Accuracy: 99.98% | Test loss: 0.08765, Test acc: 98.21%\n",
      "Epoch: 180 | Loss: 0.01756, Accuracy: 99.98% | Test loss: 0.08696, Test acc: 98.21%\n",
      "Epoch: 190 | Loss: 0.01590, Accuracy: 99.98% | Test loss: 0.08650, Test acc: 98.21%\n",
      "Epoch: 200 | Loss: 0.01447, Accuracy: 100.00% | Test loss: 0.08623, Test acc: 98.21%\n",
      "Epoch: 210 | Loss: 0.01323, Accuracy: 100.00% | Test loss: 0.08610, Test acc: 98.21%\n",
      "Epoch: 220 | Loss: 0.01215, Accuracy: 100.00% | Test loss: 0.08610, Test acc: 98.21%\n",
      "Epoch: 230 | Loss: 0.01120, Accuracy: 100.00% | Test loss: 0.08619, Test acc: 98.21%\n",
      "Epoch: 240 | Loss: 0.01036, Accuracy: 100.00% | Test loss: 0.08636, Test acc: 98.21%\n",
      "Epoch: 250 | Loss: 0.00962, Accuracy: 100.00% | Test loss: 0.08660, Test acc: 98.21%\n",
      "Epoch: 260 | Loss: 0.00895, Accuracy: 100.00% | Test loss: 0.08690, Test acc: 98.21%\n",
      "Epoch: 270 | Loss: 0.00836, Accuracy: 100.00% | Test loss: 0.08723, Test acc: 98.21%\n",
      "Epoch: 280 | Loss: 0.00783, Accuracy: 100.00% | Test loss: 0.08760, Test acc: 98.21%\n",
      "Epoch: 290 | Loss: 0.00734, Accuracy: 100.00% | Test loss: 0.08799, Test acc: 98.21%\n",
      "Epoch: 300 | Loss: 0.00691, Accuracy: 100.00% | Test loss: 0.08840, Test acc: 98.21%\n",
      "Epoch: 310 | Loss: 0.00651, Accuracy: 100.00% | Test loss: 0.08883, Test acc: 98.21%\n",
      "Epoch: 320 | Loss: 0.00614, Accuracy: 100.00% | Test loss: 0.08927, Test acc: 98.21%\n",
      "Epoch: 330 | Loss: 0.00581, Accuracy: 100.00% | Test loss: 0.08972, Test acc: 98.21%\n",
      "Epoch: 340 | Loss: 0.00551, Accuracy: 100.00% | Test loss: 0.09018, Test acc: 98.21%\n",
      "Epoch: 350 | Loss: 0.00523, Accuracy: 100.00% | Test loss: 0.09064, Test acc: 98.21%\n",
      "Epoch: 360 | Loss: 0.00497, Accuracy: 100.00% | Test loss: 0.09111, Test acc: 98.21%\n",
      "Epoch: 370 | Loss: 0.00473, Accuracy: 100.00% | Test loss: 0.09159, Test acc: 98.21%\n",
      "Epoch: 380 | Loss: 0.00451, Accuracy: 100.00% | Test loss: 0.09206, Test acc: 98.21%\n",
      "Epoch: 390 | Loss: 0.00430, Accuracy: 100.00% | Test loss: 0.09254, Test acc: 98.21%\n",
      "Epoch: 400 | Loss: 0.00411, Accuracy: 100.00% | Test loss: 0.09302, Test acc: 98.21%\n",
      "Epoch: 410 | Loss: 0.00393, Accuracy: 100.00% | Test loss: 0.09350, Test acc: 98.21%\n",
      "Epoch: 420 | Loss: 0.00376, Accuracy: 100.00% | Test loss: 0.09397, Test acc: 98.21%\n",
      "Epoch: 430 | Loss: 0.00361, Accuracy: 100.00% | Test loss: 0.09445, Test acc: 98.21%\n",
      "Epoch: 440 | Loss: 0.00346, Accuracy: 100.00% | Test loss: 0.09492, Test acc: 98.12%\n",
      "Epoch: 450 | Loss: 0.00333, Accuracy: 100.00% | Test loss: 0.09539, Test acc: 98.12%\n",
      "Epoch: 460 | Loss: 0.00320, Accuracy: 100.00% | Test loss: 0.09586, Test acc: 97.94%\n",
      "Epoch: 470 | Loss: 0.00308, Accuracy: 100.00% | Test loss: 0.09632, Test acc: 97.94%\n",
      "Epoch: 480 | Loss: 0.00296, Accuracy: 100.00% | Test loss: 0.09678, Test acc: 97.94%\n",
      "Epoch: 490 | Loss: 0.00285, Accuracy: 100.00% | Test loss: 0.09724, Test acc: 97.94%\n",
      "Epoch: 500 | Loss: 0.00275, Accuracy: 100.00% | Test loss: 0.09770, Test acc: 97.94%\n",
      "Epoch: 510 | Loss: 0.00266, Accuracy: 100.00% | Test loss: 0.09815, Test acc: 97.94%\n",
      "Epoch: 520 | Loss: 0.00257, Accuracy: 100.00% | Test loss: 0.09860, Test acc: 97.94%\n",
      "Epoch: 530 | Loss: 0.00248, Accuracy: 100.00% | Test loss: 0.09905, Test acc: 97.94%\n",
      "Epoch: 540 | Loss: 0.00240, Accuracy: 100.00% | Test loss: 0.09949, Test acc: 97.94%\n",
      "Epoch: 550 | Loss: 0.00232, Accuracy: 100.00% | Test loss: 0.09993, Test acc: 97.94%\n",
      "Epoch: 560 | Loss: 0.00225, Accuracy: 100.00% | Test loss: 0.10036, Test acc: 97.94%\n",
      "Epoch: 570 | Loss: 0.00218, Accuracy: 100.00% | Test loss: 0.10079, Test acc: 97.94%\n",
      "Epoch: 580 | Loss: 0.00211, Accuracy: 100.00% | Test loss: 0.10122, Test acc: 97.94%\n",
      "Epoch: 590 | Loss: 0.00205, Accuracy: 100.00% | Test loss: 0.10164, Test acc: 97.94%\n",
      "Epoch: 600 | Loss: 0.00199, Accuracy: 100.00% | Test loss: 0.10206, Test acc: 97.94%\n",
      "Epoch: 610 | Loss: 0.00193, Accuracy: 100.00% | Test loss: 0.10248, Test acc: 97.94%\n",
      "Epoch: 620 | Loss: 0.00187, Accuracy: 100.00% | Test loss: 0.10290, Test acc: 97.94%\n",
      "Epoch: 630 | Loss: 0.00182, Accuracy: 100.00% | Test loss: 0.10331, Test acc: 97.94%\n",
      "Epoch: 640 | Loss: 0.00177, Accuracy: 100.00% | Test loss: 0.10371, Test acc: 97.94%\n",
      "Epoch: 650 | Loss: 0.00172, Accuracy: 100.00% | Test loss: 0.10412, Test acc: 97.94%\n",
      "Epoch: 660 | Loss: 0.00168, Accuracy: 100.00% | Test loss: 0.10452, Test acc: 97.94%\n",
      "Epoch: 670 | Loss: 0.00163, Accuracy: 100.00% | Test loss: 0.10492, Test acc: 97.94%\n",
      "Epoch: 680 | Loss: 0.00159, Accuracy: 100.00% | Test loss: 0.10531, Test acc: 97.94%\n",
      "Epoch: 690 | Loss: 0.00155, Accuracy: 100.00% | Test loss: 0.10570, Test acc: 97.94%\n",
      "Epoch: 700 | Loss: 0.00151, Accuracy: 100.00% | Test loss: 0.10609, Test acc: 97.94%\n",
      "Epoch: 710 | Loss: 0.00147, Accuracy: 100.00% | Test loss: 0.10647, Test acc: 97.94%\n",
      "Epoch: 720 | Loss: 0.00143, Accuracy: 100.00% | Test loss: 0.10685, Test acc: 97.94%\n",
      "Epoch: 730 | Loss: 0.00140, Accuracy: 100.00% | Test loss: 0.10723, Test acc: 97.94%\n",
      "Epoch: 740 | Loss: 0.00137, Accuracy: 100.00% | Test loss: 0.10761, Test acc: 97.94%\n",
      "Epoch: 750 | Loss: 0.00133, Accuracy: 100.00% | Test loss: 0.10798, Test acc: 97.94%\n",
      "Epoch: 760 | Loss: 0.00130, Accuracy: 100.00% | Test loss: 0.10835, Test acc: 97.94%\n",
      "Epoch: 770 | Loss: 0.00127, Accuracy: 100.00% | Test loss: 0.10871, Test acc: 97.94%\n",
      "Epoch: 780 | Loss: 0.00124, Accuracy: 100.00% | Test loss: 0.10907, Test acc: 97.94%\n",
      "Epoch: 790 | Loss: 0.00122, Accuracy: 100.00% | Test loss: 0.10943, Test acc: 97.94%\n",
      "Epoch: 800 | Loss: 0.00119, Accuracy: 100.00% | Test loss: 0.10978, Test acc: 97.94%\n",
      "Epoch: 810 | Loss: 0.00116, Accuracy: 100.00% | Test loss: 0.11014, Test acc: 97.94%\n",
      "Epoch: 820 | Loss: 0.00114, Accuracy: 100.00% | Test loss: 0.11049, Test acc: 97.94%\n",
      "Epoch: 830 | Loss: 0.00111, Accuracy: 100.00% | Test loss: 0.11083, Test acc: 97.94%\n",
      "Epoch: 840 | Loss: 0.00109, Accuracy: 100.00% | Test loss: 0.11118, Test acc: 97.94%\n",
      "Epoch: 850 | Loss: 0.00107, Accuracy: 100.00% | Test loss: 0.11152, Test acc: 97.94%\n",
      "Epoch: 860 | Loss: 0.00104, Accuracy: 100.00% | Test loss: 0.11186, Test acc: 97.94%\n",
      "Epoch: 870 | Loss: 0.00102, Accuracy: 100.00% | Test loss: 0.11220, Test acc: 97.94%\n",
      "Epoch: 880 | Loss: 0.00100, Accuracy: 100.00% | Test loss: 0.11253, Test acc: 97.94%\n",
      "Epoch: 890 | Loss: 0.00098, Accuracy: 100.00% | Test loss: 0.11287, Test acc: 97.94%\n",
      "Epoch: 900 | Loss: 0.00096, Accuracy: 100.00% | Test loss: 0.11319, Test acc: 97.94%\n",
      "Epoch: 910 | Loss: 0.00094, Accuracy: 100.00% | Test loss: 0.11352, Test acc: 97.94%\n",
      "Epoch: 920 | Loss: 0.00093, Accuracy: 100.00% | Test loss: 0.11385, Test acc: 97.94%\n",
      "Epoch: 930 | Loss: 0.00091, Accuracy: 100.00% | Test loss: 0.11417, Test acc: 97.94%\n",
      "Epoch: 940 | Loss: 0.00089, Accuracy: 100.00% | Test loss: 0.11449, Test acc: 97.94%\n",
      "Epoch: 950 | Loss: 0.00087, Accuracy: 100.00% | Test loss: 0.11481, Test acc: 97.94%\n",
      "Epoch: 960 | Loss: 0.00086, Accuracy: 100.00% | Test loss: 0.11512, Test acc: 97.94%\n",
      "Epoch: 970 | Loss: 0.00084, Accuracy: 100.00% | Test loss: 0.11544, Test acc: 97.94%\n",
      "Epoch: 980 | Loss: 0.00083, Accuracy: 100.00% | Test loss: 0.11575, Test acc: 97.85%\n",
      "Epoch: 990 | Loss: 0.00081, Accuracy: 100.00% | Test loss: 0.11606, Test acc: 97.85%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# Build training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_0(X_train).squeeze() \n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) \n",
    "  \n",
    "    # 2. Calculate loss/accuracy\n",
    "    loss = loss_fn(y_logits,\n",
    "                   y_train) \n",
    "    acc = accuracy_fn(y_true=y_train, \n",
    "                      y_pred=y_pred) \n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model_0(X_test).squeeze() \n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        # 2. Caculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d6f25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ped(text, vectorizer, model):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    X = vectorizer.transform(text)\n",
    "    X = torch.tensor(X.toarray(), dtype=torch.float32).to(next(model.parameters()).device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        logits = model(X).squeeze()\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).long()\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0885ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not spam\n"
     ]
    }
   ],
   "source": [
    "text1 = \"hiii!\"\n",
    "text2 = \"England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\"\n",
    "result =  ped(text1,cv,model_0)\n",
    "print(\"Spam\" if result.item() == 1 else \"Not spam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cfc5d4",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b522d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "# torch.save(model_0.state_dict(), \"model_weights.pth\")\n",
    "torch.save(model_0, \"full_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model weights\n",
    "# model_0 = CircleModelV0().to(device)\n",
    "# model_0.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "# model_0.eval()\n",
    "# FULL MODEL\n",
    "model_0 = torch.load(\"full_model.pth\")\n",
    "model_0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3312b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cv, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
